<!doctype html>
<html lang="en">

<head>
  <meta charset="UTF-8">
  <meta content="IE=edge" http-equiv="X-UA-Compatible" />
  <meta content="text/html; charset=UTF-8" http-equiv="content-type" />
  <meta content="width=device-width, initial-scale=1" name="viewport" />

  
    
  

  
    
  

  
    
  

  

  
    
  

  <title>Microbenchmarks</title>

  
    <meta name="title" content="Microbenchmarks">
    <meta name="author" content="Junliang Hu">
    <meta name="description" content="Junliang Hu&#x27;s homepage">

    <meta property="og:type" content="website">
    <meta property="og:url" content="https://jlhu.io/2023-08/microbenchmarks/">
    <meta property="og:site_name" content="Junliang Hu 胡俊良">
    <meta property="og:title" content="Microbenchmarks">
    <meta property="og:description" content="Junliang Hu&#x27;s homepage">
    

    
    
      <meta property="twitter:card" content="summary_large_image">
      <meta property="twitter:url" content="https://jlhu.io/2023-08/microbenchmarks/">
      <meta property="twitter:title" content="Microbenchmarks">
      <meta property="twitter:description" content="Junliang Hu&#x27;s homepage">
      
    

    <link rel="canonical" href="https://jlhu.io/2023-08/microbenchmarks/">
    
    <script type="application/ld+json">
      {
          "description": "Junliang Hu's homepage",
          "url": "https://jlhu.io/2023-08/microbenchmarks/",
          "@type": "WebSite",
          "headline": "Microbenchmarks",
          "name": "Microbenchmarks",
          "author": { "@type": "Person", "name": "Junliang Hu" },
          "@context":"https://schema.org"
      }
    </script>
  

  

   
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.8/dist/katex.min.js" integrity="sha384-cpW21h6RZv/phavutF+AuVYrr+dA8xD9zs6FwLpaCct6O9ctzYFfFr4dgmgccOTx" crossorigin="anonymous"></script>
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.8/dist/contrib/auto-render.min.js" integrity="sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05" crossorigin="anonymous"></script>
    <script>
      document.addEventListener("DOMContentLoaded", function() {
          renderMathInElement(document.body, {
            // customised options
            // • auto-render specific keys, e.g.:
            delimiters: [
                {left: '$$', right: '$$', display: true},
                {left: '$', right: '$', display: false},
                {left: '\\(', right: '\\)', display: false},
                {left: '\\[', right: '\\]', display: true}
            ],
            // • rendering keys, e.g.:
            throwOnError : false
          });
      });
  </script>
  

  
    <link rel="stylesheet" href="https://jlhu.io/style.css" />
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@tabler/icons@latest/iconfont/tabler-icons.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.8/dist/katex.min.css" integrity="sha384-GvrOXuhMATgEsSwCs4smul74iXGOixntILdUW9XmUC6+HX0sLNAK3q71HotJqlAn" crossorigin="anonymous">
  
</head>

<body theme="auto">
  <div class="w">
    <header>
      
        <nav>
          
            <a href="/" >~jlhu</a>
          
            <a href="/tags" >#tags</a>
          
        </nav>
      

      
  <p>
    <a href="..">..</a>/microbenchmarks
  </p>
  <p class="post-meta">
    <time datetime="2023-08-05">2023-08-05</time>
  </p>
  <h1>Microbenchmarks</h1>

    </header>

    <main class="page-content" aria-label="Content">
      
  

  <h2 id="plan"><a href="../../2023-07/experiment-writing-planning/">Plan</a></h2>
<ul>
<li>Collection (kernel PEBS)
<ul>
<li>What is the cost for collecting one access sample?</li>
</ul>
</li>
<li>Identification (SDH)
<ul>
<li>How accurate is the identified working set compared to ground truth?</li>
</ul>
</li>
<li>Migration (no special design)
<ul>
<li>Do we really need special migration design?</li>
<li>What is the marginal cost?
<ul>
<li>How often does migration actually happen?</li>
<li>How much data to migrate each time?</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="collection">Collection</h2>
<h3 id="nimble">Nimble</h3>
<p>Nimble doesn't have its own sample collection technique.
Instead, it relies on Linux's sample source for the active/inactive list.</p>
<blockquote>
<p>we build a holistic multi-level memory solution that directly moves data between heterogeneous memories using the existing OS active/inactive page lists, eliminating another major source of software overhead in current systems.</p>
</blockquote>
<p>So, to find out how to measure the cost for collecting one sample,
we first need to determine how Linux <strong>collects</strong> samples for the active/inactive list.</p>
<p>From <a href="https://lwn.net/Articles/495543/">lwn</a>,
we can learn that the cost is mainly the active list accounting:</p>
<blockquote>
<p>The active list contains anonymous and file-backed pages that are thought (by the kernel) to be in active use by some process on the system. The inactive list, instead, contains pages that the kernel thinks might not be in use. When active pages are considered for eviction, they are first moved to the inactive list and unmapped from the address space of the process(es) using them. Thus, once a page moves to the inactive list, any attempt to reference it will generate a page fault; this &quot;soft fault&quot; will cause the page to be moved back to the active list. Pages that sit in the inactive list for long enough are eventually removed from the list and evicted from memory entirely.</p>
</blockquote>
<p>From <a href="https://elixir.bootlin.com/linux/v6.4/source/mm/swap.c#L501"><code>folio_add_lru()</code></a>,
we can learn that the accounting process can be broken down to two parts:</p>
<ul>
<li>mark the page as active via <code>folio_mark_accessed()</code> or wrapper <code>mark_page_accessed()</code></li>
<li>process a queued batch of pages and finalise the active/inactive decision via <code>lru_add_drain_cpu()</code></li>
</ul>
<blockquote>
<p>The decision on whether
to add the page to the [in]active [file|anon] list is deferred until the
folio_batch is drained. This gives a chance for the caller of <code>folio_add_lru()</code>
have the folio added to the active list using <code>folio_mark_accessed()</code></p>
</blockquote>
<p><a href="https://lpc.events/event/11/contributions/896/attachments/793/1493/slides-r2.pdf">Here</a>
is a another source for reference.</p>
<h3 id="ours">Ours</h3>
<p>Our samples are all collected through PMI.
We can calculate the total cycle count of all PMI,
then divide it by the number of samples collected.</p>
<h3 id="hemem">HeMem</h3>
<p>HeMem's samples are also collected through PMI.
But the major difference is that PMI only sends samples to the kernel.
The kernel then copy them on to a user-visible buffer (perf buffer).
HeMem constantly polls the buffer to find the samples passed from kernel.
So, the cost includes total cycles spent on:</p>
<ul>
<li>PMI handling (include copy to perf buffer)</li>
<li>polling</li>
</ul>
<h2 id="sample-collection">Sample Collection</h2>
<p>To measure sample collection performance,
we measure average time taken for collecting one sample.
For Nimble and other kernel LRU based design,
this is done via counting how many times <code>folio_referenced()</code> is called
and its total time taken via <code>native_sched_clock()/rdtsc</code> <sup class="footnote-reference"><a href="#tsc">1</a></sup>.</p>
<p>We check <code>folio_referenced()</code> because every time kernel LRU is checked,
it will inspect each page's hardware access count (<code>PTE.A</code>)
on the active and inactive list and update them accordingly.
Check <a href="../linux-active-inactive-lists/">here</a> for more details on kernel's LRU design.</p>
<p>To count invoke and cycle count we can add additional statistic items
in <code>vm_event_item</code> and <code>vmstat_text</code>.
Then use <code>count_vm_event(ITEM)</code> to make them visiable to userspace via <code>/proc/vmstat</code>.</p>
<div class="footnote-definition" id="tsc"><sup class="footnote-definition-label">1</sup>
<p>We can reliably use <code>rdtsc</code> because morden Intel processors have a fixed TSC frequency.
You can check this via <code>TscInvariant</code> CPU feature, e.g. <code>sudo cpuid -1 | rg TscInvariant</code>.
TSC check is also done at kernel boot through <code>determine_cpu_tsc_frequencies()</code>.</p>
</div>
<h3 id="nimble-1">Nimble</h3>
<p>Nimble's code cannot boot currently, we are trying to rebase it onto a newer version of Linux instead of v5.6-rc6.</p>
<table><thead><tr><th>Version</th><th>Status</th></tr></thead><tbody>
<tr><td>v5.6-rc6</td><td>Boot hang due to virtio related issue</td></tr>
<tr><td>v5.6</td><td>Boot hang due to NX violation of network drivers</td></tr>
<tr><td>v5.7</td><td>Ditto</td></tr>
<tr><td>v5.8</td><td>Compilation failed due to <code>arch/x86/entry/thunk_64.o</code></td></tr>
<tr><td>v5.9</td><td>Ditto</td></tr>
<tr><td>v6.4</td><td>Works</td></tr>
<tr><td>v6.5-rc1</td><td>Unsolved page fault in kernel space (virtio-net ok)</td></tr>
<tr><td>v6.5-rc2</td><td>Ditto (triggered in ip_vs_protocol_init)</td></tr>
<tr><td>v6.5-rc2</td><td>Works after disabling IP_VS</td></tr>
<tr><td>v6.5-rc3</td><td>Ditto (released on 7.24)</td></tr>
<tr><td>v6.5-rc4</td><td>Boot hang at virtnet_probe (released on 7.31) (Works after revert 2526612 listed <a href="https://github.com/torvalds/linux/commits/master/drivers/net/virtio_net.c">here</a>)</td></tr>
<tr><td>v6.5-rc5</td><td>Boot hang at virtnet_probe (released on 8.7)</td></tr>
<tr><td>v6.5-rc5</td><td>Still hang after disabling IP_VS</td></tr>
</tbody></table>
<p>After trying several candidate versions,
it's obvious old kernel has many unsolved problems.
It's best we can merge Nimble's code into our codebase.</p>
<p>Benefits:</p>
<ul>
<li>We gain more insight about Nimble's work, i.e. exactly what gives the most improvement</li>
<li>Our migration can reuse Nimble's code</li>
<li>Simpler bechmarking process</li>
</ul>


    </main>

    <footer>
      
  <p class="taxonomies">
    
  </p>


      
    </footer>
  </div>
</body>

</html>
